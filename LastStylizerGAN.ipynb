{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yarki\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\__init__.py:1405: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from model import *\n",
    "import datetime\n",
    "from read_utils import * # Import read_images and aug_images\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "#Check if the version is >= 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-84c4a9219f80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mAUGMENT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mAUGMENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0maug_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUG_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0maug_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNORMAL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUG_NORMAL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0maug_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLABEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUG_LABEL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NarrowStylizer\\read_utils.py\u001b[0m in \u001b[0;36maug_images\u001b[1;34m(path, aug_path, save)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maug_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maug_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdata_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NarrowStylizer\\read_utils.py\u001b[0m in \u001b[0;36mread_images\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mimlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(name, flatten, mode)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \"\"\"\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2411\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data\\\\realwaves_outputs' #Real Ocean Textures\n",
    "NORMAL_PATH = 'data\\\\normalmap_outputs' #Ocean Normals Textures\n",
    "LABEL_PATH = 'data\\\\styled_outputs' #Groudn Truth Texture Renders\n",
    "AUG_DATA_PATH ='data\\\\aug_realwaves_outputs'\n",
    "AUG_LABEL_PATH ='data\\\\aug_styled_outputs'\n",
    "AUG_NORMAL_PATH = 'data\\\\aug_normalmap_outputs'\n",
    "\n",
    "TEST_NORMAL_PATH = 'data\\\\test\\\\normal_2' #Ocean Normals Textures\n",
    "\n",
    "TEST_OUTPUT_DIR = 'generated'\n",
    "\n",
    "AUGMENT = True\n",
    "if AUGMENT:\n",
    "    aug_images(DATA_PATH, AUG_DATA_PATH, save=False)\n",
    "    aug_images(NORMAL_PATH, AUG_NORMAL_PATH, save=False)\n",
    "    aug_images(LABEL_PATH, AUG_LABEL_PATH, save=False)\n",
    "\n",
    "\n",
    "#label_images = read_images(LABEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "# DATASET PARAMETERS\n",
    "im_size = 128\n",
    "n_epochs = 1000\n",
    "batch_size = 16\n",
    "\n",
    "BLOCKS = 4 #Number of residual blocks\n",
    "\n",
    "START_LR = 1e-4 #Starting learning rate\n",
    "VGG_COEFF = 5e-5\n",
    "GAN_COEFF = 5e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_gen():\n",
    "    for filename1, filename2, filename3 in zip(os.listdir(AUG_DATA_PATH),os.listdir(AUG_NORMAL_PATH), os.listdir(AUG_LABEL_PATH)):\n",
    "        yield (np.array(sio.loadmat(os.path.join(AUG_DATA_PATH, filename1))['img_raw'])), \n",
    "        (np.array(sio.loadmat(os.path.join(AUG_NORMAL_PATH, filename2))['img_raw'])), (np.array(sio.loadmat(os.path.join(AUG_LABEL_PATH, filename3))['img_raw']))\n",
    "\n",
    "with tf.variable_scope('dataset'):\n",
    "    dset = tf.data.Dataset.from_generator(image_gen, (tf.float32, tf.float32, tf.float32), (tf.TensorShape([im_size,im_size,3]), tf.TensorShape([im_size,im_size,3]),tf.TensorShape([im_size,im_size,3])))\n",
    "    dset = dset.shuffle(1000)\n",
    "    dset = dset.repeat(n_epochs)\n",
    "    dset = dset.batch(batch_size)\n",
    "    dset = dset.prefetch(4)\n",
    "    dset_iterator = dset.make_initializable_iterator()\n",
    "    next_batch = dset_iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Stylizer_Resnet(input_net, scope, REUSE):\n",
    "    BLOCKS = 8\n",
    "    #pad = BLOCKS * 2 * 8\n",
    "    #net = tf.pad(input_net, [[0,0], [pad,pad], [pad,pad], [0,0]], \"REFLECT\") \n",
    "    with tf.variable_scope(scope):\n",
    "        net = tf.layers.conv2d(input_net, 16, [3,3],padding='SAME', reuse=REUSE, name='conv0')\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn0')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.layers.conv2d(net, 32, [3,3],padding='SAME', strides=[2,2], reuse=REUSE, name='conv1')\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn1')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.layers.conv2d(net, 64, [3,3],padding='SAME', strides=[2,2], reuse=REUSE, name='conv2')\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn2')\n",
    "        net = tf.nn.relu(net)\n",
    "        #net = tf.layers.conv2d(net, 64, [5,5],padding='SAME', strides=[2,2], activation=tf.nn.relu, reuse=REUSE, name='conv1')\n",
    "        for i in range(BLOCKS):\n",
    "            net = ResidualBlock(net, i, REUSE)\n",
    "        #net = tf.layers.conv2d(net, 64, [5,5],padding='SAME', reuse=REUSE, name='conv5')\n",
    "        #net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn6')\n",
    "        #net = tf.nn.relu(net)\n",
    "        #net = tf.image.resize_images(net, size=[im_size,im_size], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        net = tf.layers.conv2d_transpose(net, 64, [3,3], strides=[2,2], padding='SAME', reuse=REUSE, name='deconv1')\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn5')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.layers.conv2d_transpose(net, 32, [3,3],strides=[2,2], padding='SAME', reuse=REUSE, name='deconv2')\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn6')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.layers.conv2d(net, 16, [3,3],padding='SAME', reuse=REUSE, name='conv6')\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='bn7')\n",
    "        net = tf.nn.relu(net)\n",
    "        net = tf.layers.conv2d(net, 3, [3,3],padding='SAME', reuse=REUSE, name='conv7')\n",
    "        net = tf.nn.tanh(net)\n",
    "        return net\n",
    "        \n",
    "def Discriminator(net, scope, REUSE):\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn0')\n",
    "        net = tf.layers.conv2d(net, 32, [5,5], strides=[1,1],padding='SAME', reuse=REUSE, name='d_conv1')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn1')\n",
    "        \n",
    "        net = tf.layers.conv2d(net, 32, [5,5], strides=[2,2],padding='SAME', reuse=REUSE, name='d_conv1_2')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn1_2')\n",
    "        \n",
    "        \n",
    "        \n",
    "        net = tf.layers.conv2d(net, 64, [5,5],strides=[1,1],padding='SAME', reuse=REUSE, name='d_conv2')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn2')\n",
    "        \n",
    "        net = tf.layers.conv2d(net, 64, [5,5],strides=[2,2],padding='SAME', reuse=REUSE, name='d_conv2_2')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn2_2')\n",
    "        \n",
    "        \n",
    "        \n",
    "        net = tf.layers.conv2d(net, 128, [5,5], strides=[1,1],padding='SAME', reuse=REUSE, name='d_conv3')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn3')\n",
    "        \n",
    "        net = tf.layers.conv2d(net, 128, [5,5], strides=[2,2],padding='SAME', reuse=REUSE, name='d_conv3_2')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn3_2')\n",
    "        \n",
    "        \n",
    "        \n",
    "        net = tf.layers.conv2d(net, 256, [5,5], strides=[1,1],padding='SAME', reuse=REUSE, name='d_conv4')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn4')\n",
    "        \n",
    "        net = tf.layers.conv2d(net, 256, [5,5], strides=[2,2],padding='SAME', reuse=REUSE, name='d_conv4_2')\n",
    "        net = lrelu(net, 0.2)\n",
    "        net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn4_2')\n",
    "        \n",
    "        net = tf.layers.conv2d(net, 256, [3,3], strides=[2,2],padding='SAME', reuse=REUSE, name='d_conv5')\n",
    "        #net = lrelu(net, 0.2)\n",
    "        #net = tf.layers.batch_normalization(net, reuse=REUSE, name='d_bn5')\n",
    "\n",
    "        net = tf.contrib.layers.flatten(net)\n",
    "        net = tf.layers.dense(net, 128, activation=tf.nn.relu, reuse=REUSE, name='d_dense1')\n",
    "        net = tf.layers.dense(net, 1, reuse=REUSE, name='d_dense2')\n",
    "        \n",
    "    return net\n",
    "    \n",
    "def lrelu(x, alpha):\n",
    "    return tf.nn.relu(x) - alpha * tf.nn.relu(-x)\n",
    "    \n",
    "def ResidualBlock(net, id, REUSE):\n",
    "    #_, rows, cols, channels = [i.value for i in net.get_shape()]\n",
    "    layer_1 = tf.layers.conv2d(net, 64, [5,5],padding='SAME', reuse=REUSE, name='res_conv%d_1' % id)\n",
    "    bn_1 = tf.nn.relu(tf.layers.batch_normalization(layer_1, reuse=REUSE, name='res_bn%d_1' % id))\n",
    "    \n",
    "    layer_2 = tf.layers.conv2d(bn_1, 64, [5,5],padding='SAME', reuse=REUSE, name='res_conv%d_2' % id)  #tf.slice(net,[0,2,2,0], [batch_size,rows-4,cols-4,channels])\n",
    "    bn_2 = tf.layers.batch_normalization(layer_2, reuse=REUSE, name='res_bn%d_2' % id) +  net \n",
    "    return bn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = START_LR\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.9, staircase=True)\n",
    "data = next_batch[0]\n",
    "normals = next_batch[1]\n",
    "labels = next_batch[2]\n",
    "\n",
    "#Form the generator\n",
    "predictions = Stylizer_Resnet(normals, 'generator', False)\n",
    "\n",
    "#VGG inputs for ground truth and generated images\n",
    "t_target_image_224 = tf.image.resize_images(labels, size=[224, 224], method=0, align_corners=False) # resize_target_image_for_vgg # http://tensorlayer.readthedocs.io/en/latest/_modules/tensorlayer/layers.html#UpSampling2dLayer\n",
    "t_predict_image_224 = tf.image.resize_images(predictions, size=[224, 224], method=0, align_corners=False) # resize_generate_image_for_vgg\n",
    "\n",
    "#VGG outputs for ground truth and generated images\n",
    "_, vgg_target_emb = Vgg19_simple_api((t_target_image_224+1)/2, reuse=False)\n",
    "_, vgg_predict_emb = Vgg19_simple_api((t_predict_image_224+1)/2, reuse=True)\n",
    "    \n",
    "#Form the discriminator for real and fake images\n",
    "d_real_output = Discriminator(data, 'discriminator', False)\n",
    "d_fake_output = Discriminator(predictions, 'discriminator', True)\n",
    "    \n",
    "#Collect the generator and discriminator variables into seperate collections\n",
    "g_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "d_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "\n",
    "r_labels = tf.ones(dtype='float32', shape=[batch_size,1]) + tf.random_uniform(minval=-1.0, shape=[batch_size,1]) * 0.2\n",
    "f_labels = tf.zeros(dtype='float32', shape=[batch_size,1]) + tf.random_uniform(minval=0.0, shape=[batch_size,1]) * 0.2\n",
    "\n",
    "print(\"Model is built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy_with_logits(x, y):\n",
    "      try:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=y)\n",
    "      except:\n",
    "        return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, targets=y)\n",
    "\n",
    "#Form VGG and MSE losses.\n",
    "vgg_loss = VGG_COEFF * tl.cost.mean_squared_error(vgg_predict_emb.outputs, vgg_target_emb.outputs, is_mean=True)\n",
    "mse_loss = tl.cost.mean_squared_error(predictions , labels, is_mean=True)\n",
    "\n",
    "\n",
    "#Form GAN losses\n",
    "d_loss_real = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_real_output, r_labels))\n",
    "d_loss_fake = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_fake_output, f_labels))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "g_gan_loss = GAN_COEFF *  tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_fake_output, r_labels))\n",
    "\n",
    "\n",
    "g_loss = mse_loss + vgg_loss + g_gan_loss\n",
    "\n",
    "#Form train ops\n",
    "g_train = tf.train.AdamOptimizer(learning_rate,beta1=0.5, beta2= 0.999).minimize(g_loss, var_list=g_vars)\n",
    "vgg_train = tf.train.AdamOptimizer(learning_rate,beta1=0.5, beta2= 0.999).minimize(g_loss, var_list=g_vars)\n",
    "d_train = tf.train.AdamOptimizer(learning_rate,beta1=0.5, beta2= 0.999).minimize(d_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(dset_iterator.initializer)\n",
    "saver = tf.train.Saver()\n",
    "#saver.restore(sess,'models/model4.ckpt') #Uncomment to load model from ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the VGG model courtesy of machrisaa\n",
    "\n",
    "vgg19_npy_path = \"vgg19.npy\"\n",
    "\n",
    "if not os.path.isfile(vgg19_npy_path):\n",
    "\n",
    "    print(\"Please download vgg19.npz from : https://github.com/machrisaa/tensorflow-vgg\")\n",
    "else:\n",
    "\n",
    "    npz = np.load(vgg19_npy_path, encoding='latin1').item()\n",
    "    params = []\n",
    "\n",
    "    for val in sorted( npz.items() ):\n",
    "\n",
    "        W = np.asarray(val[1][0])\n",
    "\n",
    "        b = np.asarray(val[1][1])\n",
    "\n",
    "        print(\"  Loading %s: %s, %s\" % (val[0], W.shape, b.shape))\n",
    "\n",
    "        params.extend([W, b])\n",
    "\n",
    "    tl.files.assign_params(sess, params, net_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.run(dset_iterator.initializer)\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        i += 1\n",
    "        _,d_l = sess.run([d_train, d_loss])\n",
    "        _,g_l = sess.run([g_train, vgg_loss])\n",
    "        mse_l = sess.run(mse_loss)\n",
    "        #d_l = 0\n",
    "        if i % 10 == 0:\n",
    "            print('Loss for iteration %d D: %f G: %f MSE: %f' % (i, d_l, g_l, mse_l))\n",
    "        if np.isnan(mse_l):\n",
    "            break\n",
    "        if i % 100 == 0:\n",
    "            if not np.isnan(mse_l):\n",
    "                path = os.path(\"models\", \"MODEL_NAME\" + \".ckpt\")\n",
    "                save_path = saver.save(sess, path)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End of dataset\")  # ==> \"End of dataset\"\n",
    "        sess.run(dset_iterator.initializer)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_op = (predictions, normals, labels, data)\n",
    "A = sess.run(output_op)\n",
    "print(A[0].shape)\n",
    "print(np.max(A[0]))\n",
    "im3 = A[3][0]/2+0.5\n",
    "im0 = A[0][0]/2+0.5\n",
    "im1 = A[1][0]/2+0.5\n",
    "im2 = A[2][0]/2+0.5\n",
    "print(im1.shape)\n",
    "print(np.max(A[2]))\n",
    "print(np.min(A[2]))\n",
    "plot = plt.figure(1)\n",
    "plt.subplot(141)\n",
    "plt.imshow(im3)\n",
    "plt.subplot(142)\n",
    "plt.imshow(im1)\n",
    "plt.subplot(143)\n",
    "plt.imshow(im0)\n",
    "plt.subplot(144)\n",
    "plt.imshow(im2, vmin=-1.0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_normal_input = tf.placeholder(dtype='float32', shape=[1,1024,1024,3])\n",
    "test_prediction = Stylizer_Resnet(test_normal_input, 'generator', REUSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_normal_ims = read_images(TEST_NORMAL_PATH)[:,:,:,0:3]\n",
    "train_normal_ins = read_images(NORMAL_PATH)[:,:,:,0:3]\n",
    "train_label_ins = read_images(LABEL_PATH)[:,:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(250):\n",
    "\n",
    "    print(test_normal_ims[k:k+1][0].shape)\n",
    "    test_normal = test_normal_ims[k:k+1] if k==0 else (test_normal_ims[k-1:k] + test_normal_ims[k:k+1])/2\n",
    "    test_normal = test_normal-np.min(test_normal)\n",
    "    test_normal = test_normal/np.max(test_normal)\n",
    "    modifier = 0.45\n",
    "    test_normal =(test_normal-modifier)*2\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    test_out = sess.run(test_prediction, feed_dict={test_normal_input:test_normal })\n",
    "    end = datetime.datetime.now() - start\n",
    "    test_out = test_out/2+0.5\n",
    "    scipy.misc.imsave(TEST_OUTPUT_PATH+'/%0.3d.jpg' % k, test_out.squeeze())\n",
    "    \n",
    "    print(end,k)\n",
    "k = 0\n",
    "print(test_out.shape)\n",
    "plot = plt.figure(1)\n",
    "plt.subplot(142)\n",
    "plt.imshow(test_normal.squeeze()/2 + 0.5)\n",
    "plt.subplot(143)\n",
    "plt.imshow(test_out.squeeze())\n",
    "plt.subplot(144)\n",
    "plt.imshow(train_label_ins[k])\n",
    "plt.figure(2)\n",
    "plt.imshow(test_out.squeeze())\n",
    "plt.figure(3)\n",
    "plt.imshow(test_normal.squeeze()/2.5 + 0.5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
